<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ML Interview Questions List | Harshwardhan Sanjay Fartale </title> <meta name="author" content="Harshwardhan Sanjay Fartale"> <meta name="description" content="A list of all commonly asked questions I encountered in ML Interviews"> <meta name="keywords" content="harshwardhan fartale, harshwardhan, portfolio, Harsh"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8F%B0&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emharsha1812.github.io/blog/2025/ml-interview/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Harshwardhan</span> Sanjay Fartale </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Harshwardhan </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">KB </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/stats/">stats </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/frompapertocode/">Paper2code </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <style>ul.task-list input[type="checkbox"]:checked{accent-color:aqua!important}</style> <div class="post"> <header class="post-header"> <h1 class="post-title">ML Interview Questions List</h1> <p class="post-meta"> Created in September 17, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> machine-learning</a>   ·   <a href="/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="technical-questions-ml--dl--nlp--cv--llm">Technical questions (ML / DL / NLP / CV / LLM)</h1> <p>Below are categorized technical questions you might be asked in interviews. I grouped them so you can focus practice by area.</p> <h2 id="fundamentals--math">Fundamentals &amp; Math</h2> <ol> <li>Define bias–variance tradeoff and how you would diagnose it.</li> <li>Derive gradient descent update for a simple linear regression and explain convergence conditions.</li> <li>Explain cross-entropy loss and why it is used for classification.</li> <li>What is softmax? Why can naive softmax be numerically unstable and how to fix it?</li> <li>Explain L1 vs L2 regularization and when to use each.</li> <li>What is Bayes’ theorem and how is it used in probabilistic models?</li> <li>Show how backpropagation works for a 2-layer neural network (write equations).</li> <li>Explain vanishing/exploding gradients and how batch norm / residual connections mitigate them.</li> <li>What is the Jacobian and Hessian; why are they relevant to optimization?</li> <li>Explain the difference between likelihood and posterior.</li> </ol> <h2 id="optimization--training">Optimization &amp; Training</h2> <ol> <li>Compare SGD, SGD+momentum, RMSProp, and Adam (advantages / failure modes).</li> <li>What is learning rate scheduling? Describe step, cosine, linear warmup, and cyclical LR.</li> <li>How does gradient clipping work and when is it used?</li> <li>Explain batch normalization, layer normalization, and group normalization and where each is appropriate.</li> <li>What is weight decay and how is it implemented in optimizers like AdamW?</li> <li>How do you debug a training run where loss is NaN? Step-by-step checklist.</li> <li>How do you choose batch size and how does it affect generalization and training stability?</li> <li>What are common initialization schemes (Xavier/He) and why initialization matters.</li> <li>Explain mixed-precision training and loss-scaling.</li> <li>How to perform hyperparameter tuning at scale (Bayesian, grid, random)?</li> </ol> <h2 id="losses--evaluation-metrics">Losses &amp; Evaluation Metrics</h2> <ol> <li>Write the formulas for MSE, MAE, cross-entropy, focal loss, hinge loss.</li> <li>When to use AUC vs accuracy vs precision/recall vs F1?</li> <li>Explain mAP (mean Average Precision) and IoU in object detection.</li> <li>What is NLL (negative log-likelihood) and how is it related to cross-entropy?</li> <li>Explain BLEU, ROUGE, and METEOR for NLP evaluation — strengths/weaknesses.</li> <li>How to evaluate a medical imaging model where false negatives are costly?</li> <li>What is calibration and how to measure and improve it?</li> <li>Explain confusion matrix and derived metrics.</li> <li>How to evaluate ranked retrieval systems (MRR, NDCG, precision\@k).</li> <li>How do you measure model robustness and adversarial vulnerability?</li> </ol> <h2 id="convolutional-neural-networks--computer-vision">Convolutional Neural Networks / Computer Vision</h2> <ol> <li>Explain what a convolution operation does (mathematically and intuitively).</li> <li>What are depthwise separable convolutions and where are they used?</li> <li>Describe residual blocks (ResNet) and why they enable deeper networks.</li> <li>Explain dilated/atrous convolutions and use-cases.</li> <li>Describe Feature Pyramid Networks (FPN) and why they help detection/segmentation.</li> <li>Differences between FCN, U-Net, and UNet++ for segmentation.</li> <li>How do object detectors like Faster R-CNN differ from SSD / YOLO?</li> <li>How does Non-Maximum Suppression work? Problems and improvements.</li> <li>Explain anchor boxes and anchor-free detection approaches.</li> <li>What are common data augmentations for images and how can augmentation bias models?</li> </ol> <h2 id="transformer-architectures--attention">Transformer Architectures &amp; Attention</h2> <ol> <li>Derive scaled dot-product attention and explain the role of the scaling factor.</li> <li>What is multi-head attention and why multiple heads help?</li> <li>Explain positional encodings and alternatives (learned, rotary).</li> <li>What is layer normalization placement (pre-norm vs post-norm) and tradeoffs?</li> <li>Describe transformer encoder vs decoder vs encoder-decoder.</li> <li>How does attention complexity scale with sequence length and mitigation techniques (sparse, linear attention)?</li> <li>Explain relative vs absolute positional encodings.</li> <li>What is the mathematical form of softmax attention and its computational bottlenecks?</li> <li>How do you implement causal attention for autoregressive models?</li> <li>Explain FlashAttention (high-level) or any kernel-level speedups (if asked technically).</li> </ol> <h2 id="nlp--language-modeling--llms">NLP / Language Modeling / LLMs</h2> <ol> <li>What is perplexity and how is it computed? Pros and cons.</li> <li>Explain autoregressive vs masked language models.</li> <li>What is fine-tuning vs instruction-tuning vs parameter-efficient tuning (LoRA, adapters)?</li> <li>Explain embeddings: how they are generated and evaluated.</li> <li>What is retrieval-augmented generation (RAG) and pipeline components (retriever, index, reader)?</li> <li>How to build a vector database and choose similarity metric (cosine vs dot vs L2)?</li> <li>How to mitigate hallucinations in LLMs? List strategies.</li> <li>What is chain-of-thought prompting and why does it help?</li> <li>Explain concepts of few-shot and zero-shot learning with LLMs.</li> <li>How to evaluate factuality of LLM outputs at scale?</li> </ol> <h2 id="self-supervised--contrastive-learning">Self-supervised &amp; Contrastive Learning</h2> <ol> <li>Explain contrastive loss (InfoNCE) and negative sampling.</li> <li>What are SimCLR, MoCo, BYOL high-level differences?</li> <li>How does contrastive learning apply to multimodal (image-text) setups?</li> <li>What are pretext tasks for self-supervision in vision and NLP?</li> <li>Describe masked autoencoding (MAE) and why it works.</li> </ol> <h2 id="generative-models-vaes--gans--diffusion">Generative Models (VAEs / GANs / Diffusion)</h2> <ol> <li>Explain the VAE objective and ELBO derivation.</li> <li>What are mode collapse and instabilities in GANs? How to mitigate?</li> <li>Explain diffusion models (forward + reverse process) at a high level.</li> <li>Compare VAEs, GANs, and diffusion models for image generation.</li> <li>How to evaluate generative models (FID, IS, human eval)?</li> </ol> <h2 id="sequence-models--time-series">Sequence Models &amp; Time Series</h2> <ol> <li>Compare RNN, LSTM, GRU, and Transformer for sequential data.</li> <li>What are teacher forcing and scheduled sampling?</li> <li>Explain temporal convolutional networks (TCN).</li> <li>How to do time-series cross-validation (walk-forward validation)?</li> <li>How to avoid leakage in time-series modeling?</li> </ol> <h2 id="graph-ml">Graph ML</h2> <ol> <li>What is a GNN (GCN/GAT) and how message passing works?</li> <li>How do you create graph features for fraud detection?</li> <li>What is node2vec? How does it differ from classical embeddings?</li> <li>Describe graph sampling strategies for scaling GNNs.</li> <li>Explain transductive vs inductive graph learning.</li> </ol> <h2 id="model-compression-serving--inference">Model Compression, Serving &amp; Inference</h2> <ol> <li>Describe quantization (post-training and quant-aware training).</li> <li>What is pruning (structured vs unstructured) and how to retrain after pruning?</li> <li>Explain knowledge distillation and student-teacher training.</li> <li>How to design a low-latency inference pipeline for on-device LLMs?</li> <li>How do you benchmark model latency and throughput? Important metrics.</li> </ol> <h2 id="safety-privacy--ethical-ml">Safety, Privacy &amp; Ethical ML</h2> <ol> <li>Define differential privacy (ε, sensitivity) and DP-SGD basics.</li> <li>Explain federated learning high-level and challenges (heterogeneity, communication).</li> <li>What is model inversion and membership inference? Mitigations?</li> <li>How to audit a model for bias and unfairness? Procedure and metrics.</li> <li>Considerations for medical/clinical ML deployment (regulatory, interpretability).</li> </ol> <h2 id="scaling-distributed-training--systems">Scaling, Distributed Training &amp; Systems</h2> <ol> <li>What is data-parallel vs model-parallel training? Pros/cons.</li> <li>Explain gradient accumulation and when to use it.</li> <li>Describe pipeline parallelism and challenges.</li> <li>How to handle large token contexts in training (memory &amp; compute strategies).</li> <li>Explain sharded optimizer states (ZeRO stages) at a high level.</li> </ol> <h2 id="practical-coding--debugging--whiteboard-style">Practical Coding &amp; Debugging / Whiteboard-style</h2> <ol> <li>Write pseudocode for a training loop with data loader, forward, loss, backward, optimizer step.</li> <li>Given a model with sudden accuracy drop on validation, list systematic debug steps.</li> <li>How to implement custom Dataset and DataLoader in PyTorch for multi-modal data?</li> <li>How to profile a PyTorch training step and find bottlenecks?</li> <li>Implement (or explain) a numerically-stable softmax cross-entropy in code.</li> </ol> <h2 id="advanced--researchy">Advanced / Researchy</h2> <ol> <li>How to design an ablation study and report it convincingly?</li> <li>Explain NTK or the lottery ticket hypothesis at a high level.</li> <li>How to read and critique a ML paper (method, experiments, baselines)?</li> <li>Tips to ensure reproducibility across hardware and randomness.</li> <li>How would you formulate a novel research question in your domain (e.g., low-cost fundus screening)?</li> </ol> <hr> <h1 id="behavioral-questions">Behavioral questions</h1> <p>(Use STAR: Situation, Task, Action, Result — prep concise 1–2 min answers)</p> <ol> <li>Tell me about yourself / walk me through your resume. </li> <li>Describe a challenging technical problem you solved end-to-end.</li> <li>Tell me about a time your project failed — what happened and what you learned?</li> <li>Describe a conflict with a teammate and how you resolved it.</li> <li>Give an example where you led or mentored others.</li> <li>Describe how you prioritize work when you have multiple deadlines.</li> <li>Tell me about a time you had to convince stakeholders to change direction.</li> <li>Describe a time you improved a process (codebase, CI/CD, data pipeline).</li> <li>How do you handle criticism of your code or design?</li> <li>Tell me about a time you had to learn a new technology quickly for a project.</li> <li>Describe a time when you made a tradeoff for product deadlines (quality vs speed).</li> <li>Give an example of a time you took ownership beyond your job description.</li> <li>How do you approach giving and receiving feedback?</li> <li>Tell me about a challenging stakeholder (clinician, customer) in a healthcare project.</li> <li>Describe a time you had to explain a complex technical idea to a non-technical audience.</li> </ol> <hr> <h1 id="targeted-questions-project---resume-specific">Targeted questions (project- &amp; resume-specific)</h1> <p>Below are focused prompts tied to the projects and roles on your resume (use these to prepare deep dives &amp; demos). </p> <h2 id="aifred--local-coding-assistant">AIFred / Local coding assistant</h2> <ol> <li>Explain the full architecture (ASR → retriever → LLM → UI) and reasons for each component.</li> <li>Why pick an on-device LLM (privacy/latency) and what compromises did you accept?</li> <li>How did you select and build the retrieval corpus? Embedding model, chunking, indexing?</li> <li>How did you measure and optimize end-to-end latency (numbers and techniques)?</li> <li>How did you handle user privacy and local storage encryption?</li> <li>Describe a bug/perf issue you solved in the Electron/Streamlit UI.</li> <li>How would you extend the system to support multi-language code completion?</li> <li>How do you keep the assistant up-to-date without uploading user code?</li> </ol> <h2 id="fundusai--smartphone-fundus-imaging">FundusAI / Smartphone fundus imaging</h2> <ol> <li>Walk through the imaging pipeline — optics, capture, preprocessing, model inference.</li> <li>How did you validate labels and what inter-rater agreement metrics did you use?</li> <li>Describe the hardware adapter (3D-printed) constraints and how they affect model input.</li> <li>What clinical metrics did you optimize for and why?</li> <li>How did you ensure the model is robust to lighting and device variability?</li> <li>What are deployment and regulatory considerations for a screening tool?</li> <li>Present an example false positive &amp; false negative and how you’d fix them.</li> </ol> <h2 id="document-tampering--yolov8-project">Document Tampering / YOLOv8 Project</h2> <ol> <li>Why YOLOv8 for tampering detection — performance vs complexity?</li> <li>How did you annotate tampered regions and ensure label consistency?</li> <li>How did you evaluate generalization to unseen tampering types?</li> <li>How did you decide metric thresholds and tradeoff precision vs recall?</li> <li>Describe data augmentation and synthetic tamper generation (if used).</li> </ol> <h2 id="fraud-detection--graph-rag">Fraud detection &amp; Graph-RAG</h2> <ol> <li>Explain the graph schema you used (nodes, edges, attributes).</li> <li>Walk through a production alert path: ingestion → scoring → human review.</li> <li>How did you measure business impact (recovered $ / false alert rate)?</li> <li>How do you handle evolving fraud patterns and model drift?</li> <li>Why use Graph-RAG for retrieval, and how does it improve answers over plain RAG?</li> </ol> <h2 id="open-source-teaching--writing">Open-source, Teaching &amp; Writing</h2> <ol> <li>Examples of PRs you led — what was the technical challenge and community outcome?</li> <li>How did you structure tutorials / workshops for non-research audiences?</li> <li>How do you measure impact of technical writing (downloads, stars, adoption)?</li> <li>How do you ensure documentation stays up to date with code?</li> </ol> <h2 id="gpu--performance--triton-if-on-resume">GPU / Performance / Triton (if on resume)</h2> <ol> <li>Explain kernel memory access patterns and common optimizations (tiling, shared memory).</li> <li>Describe a profiling workflow (Nsight / profiler) and one optimization you implemented.</li> <li>How would you convert a slow PyTorch op to a Triton kernel (high-level)?</li> </ol> <hr> <p>If you want, I can now:</p> <ul> <li>Expand <strong>any one</strong> category into 50+ practice questions with answers.</li> <li>Generate concise <strong>model answers / formulas</strong> (math-focused) for the top 30 technical items.</li> <li>Produce <strong>STAR-formatted behavioral answers</strong> based on your resume content.</li> </ul> <p>Which of those should I do next?</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/welcome/">Welcome!</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/xgboost/">Newton Boosting &amp; XGBoost</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/ml-questions/">Commonly Asked Questions in ML Interviews</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/nondeterminism/">On Defeating Nondeterminism in LLM Inference</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/rsquared/">R squared in Machine Learning</a> </li> </div> <script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll(".task-list-item-checkbox").forEach(e=>{e.removeAttribute("disabled")})});</script> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Harshwardhan Sanjay Fartale. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/tabs.min.js?b8748955e1076bbe0dabcf28f2549fdc"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-harshwardhan",title:"Harshwardhan",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-kb",title:"KB",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-projects",title:"projects",description:"Projects that I built over the course of my journey",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-stats",title:"stats",description:"",section:"Navigation",handler:()=>{window.location.href="/stats/"}},{id:"nav-cv",title:"cv",description:"My Resume. You can download it from the button right there \ud83d\udc49",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-paper2code",title:"Paper2code",description:"A collection of paper-to-code implementations. This page serves as a testament to my skills in deciphering research papers and translating theoretical concepts into functional code.",section:"Navigation",handler:()=>{window.location.href="/frompapertocode/"}},{id:"nav-teaching",title:"teaching",description:"Highlights of teaching experience and contributions",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-newton-boosting-amp-xgboost",title:"Newton Boosting & XGBoost",description:"A complete guide to XGBoost",section:"Posts",handler:()=>{window.location.href="/blog/2025/xgboost/"}},{id:"post-commonly-asked-questions-in-ml-interviews",title:"Commonly Asked Questions in ML Interviews",description:"A list of all commonly asked questions I encountered in ML Interviews",section:"Posts",handler:()=>{window.location.href="/blog/2025/ml-questions/"}},{id:"post-ml-interview-questions-list",title:"ML Interview Questions List",description:"A list of all commonly asked questions I encountered in ML Interviews",section:"Posts",handler:()=>{window.location.href="/blog/2025/ml-interview/"}},{id:"post-on-defeating-nondeterminism-in-llm-inference",title:"On Defeating Nondeterminism in LLM Inference",description:"Exploring strategies to mitigate nondeterminism in large language model inference.",section:"Posts",handler:()=>{window.location.href="/blog/2025/nondeterminism/"}},{id:"post-r-squared-in-machine-learning",title:"R squared in Machine Learning",description:"Meaning, Explanation & more",section:"Posts",handler:()=>{window.location.href="/blog/2025/rsquared/"}},{id:"post-common-nlp-doubts",title:"Common NLP Doubts",description:"NLP Interview Questions",section:"Posts",handler:()=>{window.location.href="/blog/2025/nlp-questions/"}},{id:"post-training-a-simple-bigram-character-level-model-on-tiny-stories",title:"Training a simple bigram character level model on tiny stories",description:"Training a simple bigram character level model on tiny stories",section:"Posts",handler:()=>{window.location.href="/blog/2025/bigram/"}},{id:"post-machine-learning-and-ai-resources",title:"Machine Learning and AI Resources",description:"A collection of links to essential courses on machine learning, deep learning, natural language processing, and artificial intelligence.",section:"Posts",handler:()=>{window.location.href="/blog/2025/nptel-ml/"}},{id:"post-python-notes",title:"Python Notes",description:"A collection of Python notebooks for quick reference",section:"Posts",handler:()=>{window.location.href="/blog/2025/python-notes/"}},{id:"post-kan-kolmogorov-arnold-networks",title:"KAN (Kolmogorov-Arnold Networks)",description:"An Alternative to traditional MLPs",section:"Posts",handler:()=>{window.location.href="/blog/2025/kan/"}},{id:"post-a-visit-to-hungarian-mathematics",title:"A Visit to Hungarian Mathematics",description:"Why Hungarians are so darn good at mathematics ?",section:"Posts",handler:()=>{window.location.href="/blog/2024/hungarian-mathematics/"}},{id:"post-welcome",title:'Welcome! <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"Hi! My name is Harshwardhan Fartale. I am an Active Machine learning enthusiast. I studied electrical engineering at National Institute of Technology, Hamirpur and currently serving as a project associate at Indian Institute of Science Bangalore.",section:"Posts",handler:()=>{window.open("https://emharsha1812.github.io/tinkerwithml/","_blank")}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"papers2code-attention-is-all-you-need-transformer-implementation",title:"Attention Is All You Need - Transformer Implementation",description:"Complete PyTorch implementation of the Transformer architecture",section:"Papers2code",handler:()=>{window.location.href="/papers2code/attention-is-all-you-need"}},{id:"projects-codeitup",title:"CodeItUp",description:"A versatile online code editor with multi-language support",section:"Projects",handler:()=>{window.location.href="/projects/codeitup/"}},{id:"projects-alfred",title:"Alfred",description:"Your Local AI Coding Butler",section:"Projects",handler:()=>{window.location.href="/projects/llm/"}},{id:"projects-pulse",title:"PULSE",description:"A comprehensive Python library for synthetic sensor data generation",section:"Projects",handler:()=>{window.location.href="/projects/pulse/"}},{id:"projects-tinker-with-machine-learning",title:"Tinker with Machine Learning",description:"A curated place for all my AI learnings. Clearly explained",section:"Projects",handler:()=>{window.location.href="/projects/tinkerwithml/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%68%61%72%73%68%77%61%72%64%68%61%6E%66%61%72%74%61%6C%65.%6E%69%74%68@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-whatsapp",title:"WhatsApp",section:"Socials",handler:()=>{window.open("https://wa.me/919317439486","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/emharsha1812","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/emharsha1812","_blank")}},{id:"socials-kaggle",title:"Kaggle",section:"Socials",handler:()=>{window.open("https://www.kaggle.com/emharsha1812","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>