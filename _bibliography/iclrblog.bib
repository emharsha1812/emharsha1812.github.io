## LLM Generated Misinformation
@misc{chen2024llmgeneratedmisinformationdetected,
      title={Can LLM-Generated Misinformation Be Detected?}, 
      author={Canyu Chen and Kai Shu},
      year={2024},
      eprint={2309.13788},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.13788}, 
}

@inproceedings{
singh2025on,
title={On the Limitations of {LLM}-Synthesized Social Media Misinformation Moderation},
author={Sahajpreet Singh and Jiaying Wu and Svetlana Churina and Kokil Jaidka and Min-Yen Kan},
booktitle={I Can't Believe It's Not Better: Challenges in Applied Deep Learning},
year={2025},
url={https://openreview.net/forum?id=ilz2ghLgzt}
}


### Watermarking papers

@misc{liu2024unforgeablepubliclyverifiablewatermark,
      title={An Unforgeable Publicly Verifiable Watermark for Large Language Models}, 
      author={Aiwei Liu and Leyi Pan and Xuming Hu and Shu'ang Li and Lijie Wen and Irwin King and Philip S. Yu},
      year={2024},
      eprint={2307.16230},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.16230}, 
}

@misc{liu2024semanticinvariantrobustwatermark,
      title={A Semantic Invariant Robust Watermark for Large Language Models}, 
      author={Aiwei Liu and Leyi Pan and Xuming Hu and Shiao Meng and Lijie Wen},
      year={2024},
      eprint={2310.06356},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2310.06356}, 
}

@misc{gu2024learnabilitywatermarkslanguagemodels,
      title={On the Learnability of Watermarks for Language Models}, 
      author={Chenchen Gu and Xiang Lisa Li and Percy Liang and Tatsunori Hashimoto},
      year={2024},
      eprint={2312.04469},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2312.04469}, 
}

@misc{zhao2023provablerobustwatermarkingaigenerated,
      title={Provable Robust Watermarking for AI-Generated Text}, 
      author={Xuandong Zhao and Prabhanjan Ananth and Lei Li and Yu-Xiang Wang},
      year={2023},
      eprint={2306.17439},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.17439}, 
}

@misc{hu2023unbiasedwatermarklargelanguage,
      title={Unbiased Watermark for Large Language Models}, 
      author={Zhengmian Hu and Lichang Chen and Xidong Wu and Yihan Wu and Hongyang Zhang and Heng Huang},
      year={2023},
      eprint={2310.10669},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2310.10669}, 
}

@misc{kirchenbauer2024reliabilitywatermarkslargelanguage,
      title={On the Reliability of Watermarks for Large Language Models}, 
      author={John Kirchenbauer and Jonas Geiping and Yuxin Wen and Manli Shu and Khalid Saifullah and Kezhi Kong and Kasun Fernando and Aniruddha Saha and Micah Goldblum and Tom Goldstein},
      year={2024},
      eprint={2306.04634},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2306.04634}, 
}

@misc{tian2024multiscalepositiveunlabeleddetectionaigenerated,
      title={Multiscale Positive-Unlabeled Detection of AI-Generated Texts}, 
      author={Yuchuan Tian and Hanting Chen and Xutao Wang and Zheyuan Bai and Qinghua Zhang and Ruifeng Li and Chao Xu and Yunhe Wang},
      year={2024},
      eprint={2305.18149},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.18149}, 
}


@misc{arabi2025hiddennoisetwostagerobust,
      title={Hidden in the Noise: Two-Stage Robust Watermarking for Images}, 
      author={Kasra Arabi and Benjamin Feuer and R. Teal Witter and Chinmay Hegde and Niv Cohen},
      year={2025},
      eprint={2412.04653},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.04653}, 
}


@misc{hu2025videoshieldregulatingdiffusionbasedvideo,
      title={VideoShield: Regulating Diffusion-based Video Generation Models via Watermarking}, 
      author={Runyi Hu and Jie Zhang and Yiming Li and Jiwei Li and Qing Guo and Han Qiu and Tianwei Zhang},
      year={2025},
      eprint={2501.14195},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2501.14195}, 
}

@misc{lu2025robustwatermarkingusinggenerative,
      title={Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances}, 
      author={Shilin Lu and Zihan Zhou and Jiayou Lu and Yuanzhi Zhu and Adams Wai-Kin Kong},
      year={2025},
      eprint={2410.18775},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.18775}, 
}




## SynthID by Deepmind

ï»¿@Article{Dathathri2024,
author={Dathathri, Sumanth
and See, Abigail
and Ghaisas, Sumedh
and Huang, Po-Sen
and McAdam, Rob
and Welbl, Johannes
and Bachani, Vandana
and Kaskasoli, Alex
and Stanforth, Robert
and Matejovicova, Tatiana
and Hayes, Jamie
and Vyas, Nidhi
and Merey, Majd Al
and Brown-Cohen, Jonah
and Bunel, Rudy
and Balle, Borja
and Cemgil, Taylan
and Ahmed, Zahra
and Stacpoole, Kitty
and Shumailov, Ilia
and Baetu, Ciprian
and Gowal, Sven
and Hassabis, Demis
and Kohli, Pushmeet},
title={Scalable watermarking for identifying large language model outputs},
journal={Nature},
year={2024},
month={Oct},
day={01},
volume={634},
number={8035},
pages={818-823},
abstract={Large language models (LLMs) have enabled the generation of high-quality synthetic text, often indistinguishable from human-written content, at a scale that can markedly affect the nature of the information ecosystem1--3. Watermarking can help identify synthetic text and limit accidental or deliberate misuse4, but has not been adopted in production systems owing to stringent quality, detectability and computational efficiency requirements. Here we describe SynthID-Text, a production-ready text watermarking scheme that preserves text quality and enables high detection accuracy, with minimal latency overhead. SynthID-Text does not affect LLM training and modifies only the sampling procedure; watermark detection is computationally efficient, without using the underlying LLM. To enable watermarking at scale, we develop an algorithm integrating watermarking with speculative sampling, an efficiency technique frequently used in production systems5. Evaluations across multiple LLMs empirically show that SynthID-Text provides improved detectability over comparable methods, and standard benchmarks and human side-by-side ratings indicate no change in LLM capabilities. To demonstrate the feasibility of watermarking in large-scale-production systems, we conducted a live experiment that assessed feedback from nearly 20{\thinspace}million Gemini6 responses, again confirming the preservation of text quality. We hope that the availability of SynthID-Text7 will facilitate further development of watermarking and responsible use of LLM systems.},
issn={1476-4687},
doi={10.1038/s41586-024-08025-4},
url={https://doi.org/10.1038/s41586-024-08025-4}
}
