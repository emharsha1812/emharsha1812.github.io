---
layout: post
title: On Mechanistic Interpretibility in Large Language Models
date: 2024-09-1 00:12:00
description: Why do we need to look inside an LLM? 
tags: LLMs, ai
categories: ai, llms, ml, dl,nlp
tabs: true
---




Neel Nanda makes a couple of strong arguments [here](https://www.lesswrong.com/posts/uK6sQCNMw8WKzJeCQ/a-longlist-of-theories-of-impact-for-interpretability) (15 in fact!) on why interpretibility research is needed and how it will help us resolve x-issues

